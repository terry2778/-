from DrissionPage import ChromiumPage
import pandas as pd
import time
import re
from pathlib import Path
from datetime import datetime

# ====== é…ç½®éƒ¨åˆ† ======
desktop_path = Path.home() / "Desktop"
data_dir = desktop_path / "æ·˜å®è¯„è®º_æœ€ç»ˆç‰ˆ"
data_dir.mkdir(exist_ok=True)
excel_path = data_dir / 'æ·˜å®è¯„è®º.xlsx'

# ç›®æ ‡URL
target_url = 'https://item.taobao.com/item.htm?ali_refid=a3_430620_1006%3A1151396433%3AH%3A4smcY6WxR0VtwqsXOujoRmM4W5Ixekm1%3Ab47c5780755441108402a3b445e7a5f0&ali_trackid=282_b47c5780755441108402a3b445e7a5f0&id=903871222461&mi_id=0000WhnzLg5VFiKC76N6Qrby9xRZ_UbZNBYSoiOJafjsohU&mm_sceneid=1_0_127917134_0&skuId=5764101097163&spm=a21n57.1.hoverItem.1&utparam=%7B%22aplus_abtest%22%3A%22d3ee1c0dbddfffc521358d9cb40dc355%22%7D&xxc=ad_ztc'

print("=" * 80)
print("æ·˜å®è¯„è®ºçˆ¬è™« - ç®€æ´ç‰ˆ")
print("=" * 80)
print(f"ç›®æ ‡URL: {target_url[:80]}...")
print(f"æ•°æ®ä¿å­˜åˆ°: {excel_path}")
print("=" * 80)

class TaobaoCommentCrawler:
    """æ·˜å®è¯„è®ºçˆ¬è™«ç±»"""
    
    def __init__(self):
        self.browser = ChromiumPage()
        self.comments_data = []
        self.setup_browser()
    
    def setup_browser(self):
        """è®¾ç½®æµè§ˆå™¨"""
        self.browser.set.user_agent(
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        )
        
        try:
            self.browser.set.window_size(1400, 900)
        except:
            pass
    
    def find_and_click_element(self, element_type, identifier, description):
        """æŸ¥æ‰¾å¹¶ç‚¹å‡»å…ƒç´ """
        print(f"æŸ¥æ‰¾{description}...")
        
        strategies = [
            lambda: self.browser.ele(f'xpath:{identifier}', timeout=5),
            lambda: self.browser.ele(f'css:{identifier}', timeout=5),
            lambda: self.browser.ele(f'text()={identifier}', timeout=5) if element_type == 'text' else None,
            lambda: self.browser.ele(f'@{identifier}', timeout=5) if element_type == 'attr' else None,
        ]
        
        for strategy in strategies:
            try:
                element = strategy()
                if element:
                    print(f"  æ‰¾åˆ°{description}: {identifier}")
                    element.click()
                    time.sleep(3)
                    return True
            except:
                continue
        
        print(f"  æœªæ‰¾åˆ°{description}")
        return False
    
    def navigate_to_comments(self):
        """å¯¼èˆªåˆ°è¯„è®ºé¡µé¢"""
        print("\n1. å¯¼èˆªåˆ°è¯„è®ºé¡µé¢")
        
        print(f"è®¿é—®é¡µé¢...")
        self.browser.get(target_url)
        time.sleep(8)
        
        navigation_strategies = [
            ('xpath', '//*[contains(text(), "è¯„ä»·")]', '"è¯„ä»·"æ ‡ç­¾'),
            ('xpath', '//*[contains(text(), "ç”¨æˆ·è¯„ä»·")]', '"ç”¨æˆ·è¯„ä»·"æ ‡ç­¾'),
            ('xpath', '//*[contains(text(), "å®è´è¯„ä»·")]', '"å®è´è¯„ä»·"æ ‡ç­¾'),
            ('xpath', '//*[contains(text(), "è¯„è®º")]', '"è¯„è®º"æ ‡ç­¾'),
            ('xpath', '//*[contains(text(), "æŸ¥çœ‹å…¨éƒ¨è¯„ä»·")]', '"æŸ¥çœ‹å…¨éƒ¨è¯„ä»·"æŒ‰é’®'),
            ('css', '.tb-tab-anchor[data-spm="user-evaluation"]', 'è¯„ä»·CSSé€‰æ‹©å™¨'),
        ]
        
        for strategy_type, identifier, description in navigation_strategies:
            if self.find_and_click_element(strategy_type, identifier, description):
                print(f"  æˆåŠŸè¿›å…¥è¯„è®ºé¡µé¢")
                time.sleep(5)
                return True
        
        print("  æœªèƒ½è¿›å…¥è¯„è®ºé¡µé¢ï¼Œå°è¯•åœ¨å½“å‰é¡µé¢æŸ¥æ‰¾è¯„è®º")
        return False
    
    def load_all_comments(self):
        """åŠ è½½å…¨éƒ¨è¯„è®º"""
        print("\n2. åŠ è½½å…¨éƒ¨è¯„è®º")
        
        initial_count = self.count_comments()
        print(f"  åˆå§‹è¯„è®ºæ•°: {initial_count}")
        
        load_attempts = 0
        max_attempts = 20
        no_new_comments_count = 0
        
        while load_attempts < max_attempts:
            load_attempts += 1
            
            print(f"  å°è¯• {load_attempts}: æ»šåŠ¨åŠ è½½")
            self.scroll_for_comments()
            
            if load_attempts % 3 == 0:
                self.click_load_more_buttons()
            
            current_count = self.count_comments()
            if current_count > initial_count:
                print(f"    å‘ç°æ–°è¯„è®º: {current_count - initial_count} æ¡")
                initial_count = current_count
                no_new_comments_count = 0
            else:
                no_new_comments_count += 1
                print(f"    æœªå‘ç°æ–°è¯„è®º (è¿ç»­ {no_new_comments_count} æ¬¡)")
            
            if no_new_comments_count >= 5:
                print("    è¿ç»­å¤šæ¬¡æœªå‘ç°æ–°è¯„è®ºï¼Œåœæ­¢åŠ è½½")
                break
            
            time.sleep(2)
        
        print(f"  æœ€ç»ˆè¯„è®ºæ•°: {initial_count}")
    
    def count_comments(self):
        """ç»Ÿè®¡è¯„è®ºæ•°é‡"""
        selectors = [
            'xpath://div[contains(@class, "Comment-")]',
            'xpath://div[contains(@class, "comment-")]',
            'xpath://div[contains(@class, "rate-")]',
            'xpath://div[contains(@class, "tb-rev-item")]',
        ]
        
        for selector in selectors:
            try:
                elements = self.browser.eles(selector)
                if elements:
                    return len(elements)
            except:
                continue
        
        return 0
    
    def scroll_for_comments(self):
        """æ»šåŠ¨ä»¥åŠ è½½è¯„è®º"""
        scroll_strategies = [
            (500, "è¯„è®ºåŒºåŸŸ"),
            (800, "é¡µé¢ä¸­éƒ¨"),
            (1200, "é¡µé¢åº•éƒ¨"),
            (300, "å°å¹…æ»šåŠ¨"),
            (1000, "å¤§å¹…æ»šåŠ¨"),
        ]
        
        for scroll_amount, description in scroll_strategies:
            print(f"    æ»šåŠ¨{description}: {scroll_amount}px")
            self.browser.scroll.down(scroll_amount)
            time.sleep(1.5)
    
    def click_load_more_buttons(self):
        """ç‚¹å‡»åŠ è½½æ›´å¤šæŒ‰é’®"""
        button_selectors = [
            'xpath://*[contains(text(), "åŠ è½½æ›´å¤š")]',
            'xpath://*[contains(text(), "æŸ¥çœ‹æ›´å¤š")]',
            'xpath://*[contains(text(), "æŸ¥çœ‹å…¨éƒ¨")]',
            'xpath://button[contains(@class, "load-more")]',
            'xpath://a[contains(@class, "more")]',
        ]
        
        for selector in button_selectors:
            try:
                buttons = self.browser.eles(selector)
                if buttons:
                    print(f"    æ‰¾åˆ°å¹¶ç‚¹å‡»åŠ è½½æŒ‰é’®")
                    buttons[0].click()
                    time.sleep(3)
                    return True
            except:
                continue
        
        return False
    
    def extract_comments_by_position(self):
        """é€šè¿‡å…ƒç´ ä½ç½®æå–è¯„è®º"""
        print("\n3. æå–è¯„è®º")
        
        comment_containers = self.locate_comment_containers()
        
        if not comment_containers:
            print("  æœªæ‰¾åˆ°è¯„è®ºå®¹å™¨")
            return []
        
        print(f"  æ‰¾åˆ° {len(comment_containers)} ä¸ªè¯„è®ºå®¹å™¨")
        
        all_comments = []
        
        for i, container in enumerate(comment_containers[:100]):
            try:
                comment_data = self.extract_single_comment(container, i+1)
                if comment_data and comment_data.get('è¯„è®ºå†…å®¹'):
                    all_comments.append(comment_data)
                    print(f"  æå–è¯„è®º {len(all_comments)}: {comment_data['ç”¨æˆ·å'][:10]}...")
            except Exception as e:
                continue
        
        return all_comments
    
    def locate_comment_containers(self):
        """å®šä½è¯„è®ºå®¹å™¨"""
        location_strategies = [
            lambda: self.browser.eles('xpath://div[contains(@class, "Comment-")]'),
            lambda: self.browser.eles('css:div[class*="Comment-"]'),
            lambda: self.find_elements_near_text('è¯„ä»·', 'div'),
            lambda: self.browser.eles('css:.tb-rev-item'),
            lambda: self.browser.eles('xpath://div[contains(@class, "rate-card") or contains(@class, "comment-item")]'),
        ]
        
        for strategy in location_strategies:
            try:
                elements = strategy()
                if elements and len(elements) > 0:
                    print(f"  ä½¿ç”¨ç­–ç•¥æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
                    return elements
            except:
                continue
        
        return []
    
    def find_elements_near_text(self, text, tag_name='div'):
        """æŸ¥æ‰¾æ–‡æœ¬é™„è¿‘çš„å…ƒç´ """
        try:
            text_elements = self.browser.eles(f'xpath://*[contains(text(), "{text}")]')
            
            nearby_elements = []
            for text_element in text_elements:
                parent = text_element.parent
                for _ in range(3):
                    if parent:
                        siblings = parent.eles(f'xpath:.//{tag_name}')
                        nearby_elements.extend(siblings)
                        parent = parent.parent
            
            return nearby_elements
        except:
            return []
    
    def extract_single_comment(self, container, index):
        """æå–å•ä¸ªè¯„è®º"""
        comment_data = {
            'åºå·': index,
            'ç”¨æˆ·å': 'åŒ¿åç”¨æˆ·',
            'è¯„è®ºå†…å®¹': '',
            'è¯„è®ºæ—¶é—´': '',
            'è´­ä¹°ä¿¡æ¯': ''
        }
        
        try:
            # æå–ç”¨æˆ·å
            comment_data['ç”¨æˆ·å'] = self.extract_username_from_container(container)
            
            # æå–è¯„è®ºå†…å®¹
            comment_data['è¯„è®ºå†…å®¹'] = self.extract_comment_content(container)
            
            # æå–è¯„è®ºæ—¶é—´
            comment_data['è¯„è®ºæ—¶é—´'] = self.extract_comment_time(container)
            
            # æå–è´­ä¹°ä¿¡æ¯
            comment_data['è´­ä¹°ä¿¡æ¯'] = self.extract_purchase_info(container)
            
            return comment_data
            
        except Exception as e:
            return None
    
    def extract_username_from_container(self, container):
        """ä»å®¹å™¨æå–ç”¨æˆ·å"""
        strategies = [
            lambda: self.find_in_container(container, 'css:.header-nYbpA78v span'),
            lambda: self.find_in_container(container, 'css:[class*="user"]'),
            lambda: self.find_in_container(container, 'css:[class*="name"]'),
            lambda: self.find_first_short_text(container),
        ]
        
        for strategy in strategies:
            try:
                username = strategy()
                if username and username != 'åŒ¿åç”¨æˆ·':
                    return username[:30]
            except:
                continue
        
        return 'åŒ¿åç”¨æˆ·'
    
    def find_in_container(self, container, selector):
        """åœ¨å®¹å™¨å†…æŸ¥æ‰¾å…ƒç´ """
        try:
            element = container.ele(selector)
            if element:
                text = element.text.strip() if hasattr(element, 'text') and element.text else ""
                if text and 2 <= len(text) <= 20:
                    return text
        except:
            pass
        return None
    
    def find_first_short_text(self, container):
        """æŸ¥æ‰¾ç¬¬ä¸€ä¸ªçŸ­æ–‡æœ¬"""
        try:
            all_text = container.text if hasattr(container, 'text') else ""
            lines = all_text.split('\n')
            
            for line in lines:
                line = line.strip()
                if 2 <= len(line) <= 15 and not re.search(r'[\d-]{8,}', line):
                    return line
        except:
            pass
        
        return None
    
    def extract_comment_content(self, container):
        """æå–è¯„è®ºå†…å®¹"""
        strategies = [
            lambda: self.find_content_by_class(container, 'content-uono'),
            lambda: self.find_content_by_class(container, 'contentWrapper'),
            lambda: self.find_long_text_in_container(container),
        ]
        
        for strategy in strategies:
            try:
                content = strategy()
                if content and len(content) > 10:
                    return content[:500]
            except:
                continue
        
        return ''
    
    def find_content_by_class(self, container, class_part):
        """é€šè¿‡ç±»åæŸ¥æ‰¾å†…å®¹"""
        try:
            elements = container.eles(f'css:[class*="{class_part}"]')
            for element in elements:
                title = element.attr('title')
                if title and len(title) > 10:
                    return title
                
                text = element.text.strip() if hasattr(element, 'text') and element.text else ""
                if text and len(text) > 10:
                    return text
        except:
            pass
        
        return ''
    
    def find_long_text_in_container(self, container):
        """æŸ¥æ‰¾å®¹å™¨å†…çš„é•¿æ–‡æœ¬"""
        try:
            all_text = container.text if hasattr(container, 'text') else ""
            lines = [line.strip() for line in all_text.split('\n') if len(line.strip()) > 20]
            
            if lines:
                return max(lines, key=len)
        except:
            pass
        
        return ''
    
    def extract_comment_time(self, container):
        """æå–è¯„è®ºæ—¶é—´"""
        try:
            container_text = container.text if hasattr(container, 'text') else ""
            
            patterns = [
                r'(\d{4}-\d{1,2}-\d{1,2})',
                r'(\d{1,2}æœˆ\d{1,2}æ—¥)',
                r'(\d{1,2}-\d{1,2})',
                r'(\d{1,2}/\d{1,2}/\d{4})',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, container_text)
                if match:
                    return match.group(1)
        except:
            pass
        
        return ''
    
    def extract_purchase_info(self, container):
        """æå–è´­ä¹°ä¿¡æ¯"""
        try:
            container_text = container.text if hasattr(container, 'text') else ""
            
            patterns = [
                r'å·²è´­[ï¼š:]\s*([^\n]+)',
                r'è´­ä¹°[ï¼š:]\s*([^\n]+)',
                r'è§„æ ¼[ï¼š:]\s*([^\n]+)',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, container_text)
                if match:
                    return match.group(1).strip()
        except:
            pass
        
        return ''
    
    def save_to_excel(self, comments):
        """ä¿å­˜åˆ°Excel"""
        if not comments:
            print("\nâŒ æ²¡æœ‰è¯„è®ºå¯ä¿å­˜")
            return False
        
        try:
            df = pd.DataFrame(comments)
            
            # åªä¿ç•™éœ€è¦çš„åˆ—ï¼šåºå·ã€ç”¨æˆ·åã€è¯„è®ºæ—¶é—´ã€è´­ä¹°ä¿¡æ¯ã€è¯„è®ºå†…å®¹
            column_order = ['åºå·', 'ç”¨æˆ·å', 'è¯„è®ºæ—¶é—´', 'è´­ä¹°ä¿¡æ¯', 'è¯„è®ºå†…å®¹']
            df = df[column_order]
            
            # ä¿å­˜åˆ°Excel
            df.to_excel(excel_path, index=False, engine='openpyxl')
            
            print(f"\nâœ… æˆåŠŸä¿å­˜ {len(df)} æ¡è¯„è®ºåˆ°: {excel_path}")
            
            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
            print("\nğŸ“‹ æ•°æ®é¢„è§ˆ:")
            print("=" * 80)
            for _, row in df.head(10).iterrows():
                print(f"{row['åºå·']}. [{row['ç”¨æˆ·å']}]", end="")
                if row['è¯„è®ºæ—¶é—´']:
                    print(f" ({row['è¯„è®ºæ—¶é—´']})", end="")
                print()
                
                if row['è´­ä¹°ä¿¡æ¯']:
                    print(f"   è´­ä¹°: {row['è´­ä¹°ä¿¡æ¯'][:60]}...")
                
                print(f"   å†…å®¹: {row['è¯„è®ºå†…å®¹'][:80]}...")
                print()
            
            # ä¿å­˜ä¸ºCSV
            csv_path = excel_path.with_suffix('.csv')
            df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"ğŸ“„ åŒæ—¶ä¿å­˜ä¸ºCSV: {csv_path}")
            
            return True
            
        except Exception as e:
            print(f"ä¿å­˜æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return False
    
    def save_debug_info(self):
        """ä¿å­˜è°ƒè¯•ä¿¡æ¯"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            screenshot_path = data_dir / f'screenshot_{timestamp}.png'
            self.browser.get_screenshot(as_bytes=False, path=str(screenshot_path))
            print(f"ğŸ“¸ é¡µé¢æˆªå›¾å·²ä¿å­˜: {screenshot_path}")
            
            html_path = data_dir / f'page_structure_{timestamp}.html'
            html_content = self.browser.html if hasattr(self.browser, 'html') else ""
            
            if html_content:
                with open(html_path, 'w', encoding='utf-8') as f:
                    f.write(html_content[:50000])
                
                print(f"ğŸ“ é¡µé¢ç»“æ„å·²ä¿å­˜: {html_path}")
            
        except Exception as e:
            print(f"ä¿å­˜è°ƒè¯•ä¿¡æ¯å‡ºé”™: {str(e)}")
    
    def run(self):
        """è¿è¡Œçˆ¬è™«"""
        start_time = datetime.now()
        print(f"å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            # 1. å¯¼èˆªåˆ°è¯„è®ºé¡µé¢
            self.navigate_to_comments()
            
            # 2. åŠ è½½å…¨éƒ¨è¯„è®º
            self.load_all_comments()
            
            # 3. é€šè¿‡å…ƒç´ ä½ç½®æå–è¯„è®º
            comments = self.extract_comments_by_position()
            
            # 4. ä¿å­˜ç»“æœ
            if comments:
                self.save_to_excel(comments)
                
                print(f"\nğŸ‰ çˆ¬å–å®Œæˆ!")
                print(f"æ€»è€—æ—¶: {(datetime.now() - start_time).seconds}ç§’")
                print(f"æœ‰æ•ˆè¯„è®ºæ•°: {len(comments)}")
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                print("\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
                print(f"- å¹³å‡è¯„è®ºé•¿åº¦: {sum(len(c['è¯„è®ºå†…å®¹']) for c in comments)/len(comments):.1f} å­—ç¬¦")
                
                # ç”¨æˆ·åç»Ÿè®¡
                usernames = [c['ç”¨æˆ·å'] for c in comments]
                unique_users = len(set(usernames))
                print(f"- ç‹¬ç«‹ç”¨æˆ·æ•°: {unique_users}")
            
            else:
                print("\nâŒ æœªèƒ½æå–åˆ°ä»»ä½•è¯„è®º")
                self.save_debug_info()
                
                print("\nğŸ’¡ å»ºè®®:")
                print("1. æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•æ·˜å®è´¦å·")
                print("2. æ‰‹åŠ¨æ‰“å¼€é¡µé¢ç¡®è®¤è¯„è®ºæ˜¯å¦å¯è§")
                print("3. æŸ¥çœ‹ä¿å­˜çš„æˆªå›¾å’Œé¡µé¢ç»“æ„åˆ†æ")
        
        except Exception as e:
            print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            
            self.save_debug_info()
        
        finally:
            try:
                self.browser.close()
                print("\næµè§ˆå™¨å·²å…³é—­")
            except:
                pass
        
        print(f"\nç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)

# ä¸»ç¨‹åº
if __name__ == "__main__":
    print("æ·˜å®è¯„è®ºçˆ¬è™«å¯åŠ¨...")
    
    crawler = TaobaoCommentCrawler()
    crawler.run()
